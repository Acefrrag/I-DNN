TRAINING REPORT - 04-16-23_19-49-05
 
Number of hidden layers : 9
Neurons per layer: [50, 35, 30, 30, 25, 20, 15, 15, 10]
Activation function type: ReLU
Training data size: 50000
Training epochs: 1
Training batch size:100
Training learning rate: eta =10
Training regularitation value: lambda =0
Evaluation data size: 10000
Evaluation Accuracies per epoch: 
Epoch:0 Accuracy: 991/10000
