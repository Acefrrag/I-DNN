TRAINING REPORT - 04-30-23_23-31-39
 
Number of hidden layers : 4
Neurons per layer: [30, 25, 15, 10]
Activation function type: ReLU
Training data size: 50000
Training epochs: 10
Training batch size:100
Training learning rate: eta =10
Training regularitation value: lambda =1
Evaluation data size: 10000
Evaluation Accuracies per epoch: 
Epoch:0 Accuracy: 991/10000
Epoch:1 Accuracy: 991/10000
Epoch:2 Accuracy: 991/10000
Epoch:3 Accuracy: 991/10000
Epoch:4 Accuracy: 1795/10000
Epoch:5 Accuracy: 5025/10000
Epoch:6 Accuracy: 4934/10000
Epoch:7 Accuracy: 4850/10000
Epoch:8 Accuracy: 5719/10000
Epoch:9 Accuracy: 5888/10000
